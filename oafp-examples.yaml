# oafp url="https://gist.githubusercontent.com/nmaguiar/557e12e4a840d513635b3a57cb57b722/raw/oafp-examples.yaml" in=yaml out=template path=data templatepath=tmpl sql="select * where d like '%something%'"
# oafp url="https://gist.githubusercontent.com/nmaguiar/557e12e4a840d513635b3a57cb57b722/raw/oafp-examples.yaml" in=yaml path="data[].{category:c,subCategory:s,description:d}" from="sort(category,subCategory,description)" out=ctable
#
tmpl: |-
  {{#each this}}
  {{{$sline ($acolor 'BOLD' ($concat 'ðŸ“– ' c ' | ' s)) __ 'FAINT' __ 'openBottomRect'}}}
  {{{$sline ($acolor 'ITALIC' d) __ 'FAINT' __ 'doubleLine'}}}

  {{{$acolor 'FAINT' e}}}

  {{/each}}
data:
# Grid / Java
- c: Grid
  s: Java
  d: Parse a Java stacktrace into a looping grid.
  e: |-
    HSPERF=/tmp/hsperfdata_user/12345 && oafp $HSPERF in=hsperf path=java out=grid grid="[[(title:Threads,type:chart,obj:'int threads.live:green:live threads.livePeak:red:peak threads.daemon:blue:daemon -min:0')|(title:Class Loaders,type:chart,obj:'int cls.loadedClasses:blue:loaded cls.unloadedClasses:red:unloaded')]|[(title:Heap,type:chart,obj:'bytes __mem.total:red:total __mem.used:blue:used -min:0')|(title:Metaspace,type:chart,obj:'bytes __mem.metaTotal:blue:total __mem.metaUsed:green:used -min:0')]]" loop=1
# Generic / Text
- c: Generic
  s: Text
  d: Get a json with lyrics of a song.
  e: |-
    curl -s https://api.lyrics.ovh/v1/Coldplay/Viva%20La%20Vida | oafp path="substring(lyrics,index_of(lyrics, '\n'),length(lyrics))"
# Generic / Excel
- c: Generic
  s: Excel
  d: Processes each json file in /some/data creating and updating the data.xlsx file with a sheet for each file.
  e: |-
    find /some/data -name "*.json" | xargs -I '{}' /bin/sh -c 'oafp file={} output=xls xlsfile=data.xlsx xlsopen=false xlssheet=$(echo {} | sed "s/.*\/\(.*\)\.json/\1/g" )'
- c: Generic
  s: Excel
  d: Building an Excel file with the AWS IPv4 and IPv6 ranges (1).
  e: |-
    curl https://ip-ranges.amazonaws.com/ip-ranges.json > ip-ranges.json
- c: Generic
  s: Excel
  d: Building an Excel file with the AWS IPv4 and IPv6 ranges (2).
  e: |-
    oafp ip-ranges.json path=prefixes out=xls xlsfile=aws-ip-ranges.xlsx xlssheet=ipv4
- c: Generic
  s: Excel
  d: Building an Excel file with the AWS IPv4 and IPv6 ranges (3).
  e: |-
    oafp ip-ranges.json path=ipv6_prefixes out=xls xlsfile=aws-ip-ranges.xlsx xlssheet=ipv6
# DB / H2
- c: DB
  s: H2
  d: Store the json result of a command into a H2 database table.
  e: |-
    oaf -c "\$o(listFilesRecursive('.'),{__format:'json'})" | oafp out=db dbjdbc="jdbc:h2:./data" dbuser=sa dbpass=sa dbtable=data
- c: DB
  s: H2
  d: Perform a SQL query over a H2 database.
  e: |-
    echo "select * from \"data\"" | oafp in=db indbjdbc="jdbc:h2:./data" indbuser=sa indbpass=sa out=ctable
# DB / SQLite
- c: DB
  s: SQLite
  d: Store the json result on a SQLite database table.
  e: |-
    ojob ojob.io/db/getDriver op=install db=sqlite
    oaf -c "\$o(listFilesRecursive('.'),{__format:'json'})" | oafp out=db dbjdbc="jdbc:sqlite:data.db" dbtable=data dblib=sqlite
- c: DB
  s: SQLite
  d: Perform a query over a database using JDBC.
  e: |-
    ojob ojob.io/db/getDriver op=install db=sqlite
    echo "select * from data" | oafp in=db indbjdbc="jdbc:sqlite:data.db" indbtable=data indblib=sqlite out=ctable
# Generic / Docker
- c: Docker
  s: Containers
  d: Output a table with the list of running containers.
  e: |-
    oafp cmd="docker ps --format json" input=ndjson ndjsonjoin=true path="[].{id:ID,name:Names,state:State,image:Image,networks:Networks,ports:Ports,Status:Status}" sql="select * order by networks,state,name" output=ctable
- c: Docker
  s: Stats
  d: Output a table with the docker stats broken down for each value.
  e: |-
    oafp cmd="docker stats --no-stream" in=lines linesvisual=true linesjoin=true out=ctree path="[].{containerId:\"CONTAINER ID\",pids:PIDS,name:\"NAME\",cpuPerc:\"CPU %\",memory:\"MEM USAGE / LIMIT\",memPerc:\"MEM %\",netIO:\"NET I/O\",blockIO:\"BLOCK I/O\"}|[].{containerId:containerId,pids:pids,name:name,cpuPerc:replace(cpuPerc,'%','',''),memUsage:from_bytesAbbr(split(memory,' / ')[0]),memLimit:from_bytesAbbr(split(memory,' / ')[1]),memPerc:replace(memPerc,'%','',''),netIn:from_bytesAbbr(split(netIO,' / ')[0]),netOut:from_bytesAbbr(split(netIO,' / ')[1]),blockIn:from_bytesAbbr(split(blockIO,' / ')[0]),blockOut:from_bytesAbbr(split(blockIO,' / ')[1])}" out=ctable
- c: Docker
  s: Storage
  d: Output a table with the docker volumes info.
  e: |-
    docker volume ls --format json | oafp in=ndjson ndjsonjoin=true out=ctable
- c: Docker
  s: Network
  d: Output a table with the docker networks info.
  e: |-
    docker network ls --format json | oafp in=ndjson ndjsonjoin=true out=ctable
# Mac / Brew
- c: Mac
  s: Brew
  d: List all the packages and corresponding versions installed in a Mac by brew.
  e: |-
    brew list --versions | oafp in=lines linesjoin=true path="[].split(@,' ').{package:[0],version:[1]}|sort_by(@,&package)" out=ctable
# Unix / Files
- c: Unix
  s: Files
  d: Converting the Unix's syslog into a json output.
  e: |-
    cat syslog | oafp in=raw path="split(trim(@),'\n').map(&split(@, ' ').{ date: concat([0],concat(' ',[1])), time: [2], host: [3], process: [4], message: join(' ',[5:]) }, [])"
- c: Unix
  s: Files
  d: Converting the Linux's /etc/os-release to SQL insert statements.
  e: |-
    oafp cmd="cat /etc/os-release" in=ini outkey=release path="[@]" sql="select '$HOSTNAME' \"HOST\", *" out=sql sqlnocreate=true
- c: Unix
  s: Files
  d: Parses the Linux /etc/passwd to a table order by uid and gid.
  e: |-
    oafp cmd="cat /etc/passwd" in=csv inputcsv="(withHeader: false, withDelimiter: ':')" path="[].{user:f0,pass:f1,uid:to_number(f2),gid:to_number(f3),description:f4,home:f5,shell:f6}" out=json | oafp from="notStarts(user, '#').sort(uid, gid)" out=ctable
# Unix / Generic
- c: Unix
  s: Generic
  d: "Creates, in unix, a data.ndjson file where each record is formatted from json files in /some/data"
  e: |-
    find /some/data -name "*.json" -exec oafp {} output=json \; > data.ndjson
- c: Unix
  s: Compute
  d: Parses the Linux /proc/cpuinfo into an array
  e: |-
    cat /proc/cpuinfo | sed "s/^$/---/mg" | ./oafp in=yaml path="[?not_null(@)]" out=ctree
- c: Unix
  s: Storage
  d: Parses the result of the Unix ls command
  e: |-
    ls -lad --time-style="+%Y-%m-%d %H:%M" * | oafp in=lines path="map(&split_re(@,'\\s+').{permissions:[0],id:[1],user:[2],group:[3],size:[4],date:[5],time:[6],file:[7]},[])" linesjoin=true out=ctable
- c: Unix
  s: Network
  d: Parse the result of the Linux route command
  e: |-
    route | sed "1d" | oafp in=lines linesjoin=true linesvisual=true linesvisualsepre="\s+" out=ctable
- c: Unix
  s: Network
  d: Parse the Linux 'ip tcp_metrics' command
  e: |-
    ip tcp_metrics | sed 's/^/target: /g' | sed 's/$/\n\n---\n/g' | sed 's/ \([a-z]*\) /\n\1: /g' | head -n -2 | oafp in=yaml path="[].{target:target,age:from_timeAbbr(replace(age,'[sec|\.]','','')),cwnd:cwnd,rtt:from_timeAbbr(rtt),rttvar:from_timeAbbr(rttvar),source:source}" sql="select * order by target" out=ctable
- c: Unix
  s: Network
  d: Parse the Linux 'arp' command output
  e: |-
    arp | oafp in=lines linesvisual=true linesjoin=true out=ctable
- c: Unix
  s: Network
  d: Loop over the current Linux active network connections
  e: |-
    oafp cmd="netstat -tun | sed \"1d\"" in=lines linesvisual=true linesjoin=true linesvisualsepre="\\s+(\\?\!Address)" out=ctable loop=1
- c: Unix
  s: SystemCtl
  d: Converting the Unix's systemctl list-timers
  e: |-
    systemctl list-timers | head -n -3 | oafp in=lines linesvisual=true linesjoin=true out=ctable
- c: Unix
  s: SystemCtl
  d: Converting the Unix's systemctl list-units
  e: |-
    systemctl list-units | head -n -6 | oafp in=lines linesvisual=true linesjoin=true path="[].delete(@,'')" out=ctable
- c: Unix
  s: SystemCtl
  d: Converting the Unix's systemctl list-units into an overview table
  e: |-
    systemctl list-units | head -n -6 | oafp in=lines linesvisual=true linesjoin=true path="[].delete(@,'')" sql="select \"LOAD\", \"ACTIVE SUB\", count(1) as \"COUNT\" group by \"LOAD\", \"ACTIVE SUB\"" sqlfilter=advanced out=ctable
- c: Unix
  s: Storage 
  d: Converting the Unix's df output
  e: |-
    df --output=target,fstype,size,used,avail,pcent | tail -n +2 | oafp in=lines linesjoin=true path="[].split_re(@, ' +').{filesystem:[0],type:[1],size:[2],used:[3],available:[4],use:[5]}" out=ctable
# Unix / Debian/Ubuntu
- c: Unix
  s: Debian/Ubuntu
  d: List all installed packages in a Debian/Ubuntu system
  e: |-
    apt list --installed | sed "1d" | oafp in=lines linesjoin=true path="[].split(@,' ').{pack:split([0],'/')[0],version:[1],arch:[2]}" out=ctable
# Unix / UBI
- c: Unix
  s: UBI
  d: List all installed packages in an UBI system
  e: |-
    microdnf repoquery --setopt=cachedir=/tmp --installed | oafp in=lines linesjoin=true path="[].replace(@,'(.+)\.(\w+)\.(\w+)\$','','\$1|\$2|\$3').split(@,'|').{package:[0],dist:[1],arch:[2]}" out=ctable
# Unix / Alpine
- c: Unix
  s: Alpine
  d: List all installed packages in an Alpine system
  e: |-
    apk list -I | oafp in=lines linesjoin=true path="[].replace(@,'(.+) (.+) {(.+)} \((.+)\) \[(.+)\]','','\$1|\$2|\$3|\$4').split(@,'|').{package:[0],arch:[1],source:[2],license:[3]}" out=ctable
# Unix / RedHat
- c: Unix
  s: RedHat
  d: List all installed packages in a RedHat system or rpm based system (use rpm --querytags to list all fields available)
  e: |-
    rpm -qa --qf "%{NAME}|%{VERSION}|%{PACKAGER}|%{VENDOR}|%{ARCH}\n" | oafp in=lines linesjoin=true path="[].split(@,'|').{package:[0],version:[1],packager:[2],vendor:[3],arch:[4]}" from="sort(package)" out=ctable
# Unix / OpenSUSE
- c: Unix
  s: OpenSuse
  d: List all installed packages in an OpenSuse system or zypper based system
  e: |-
    zypper se -is | egrep "^i" | oafp in=lines linesjoin=true path="[].split(@,'|').{name:[1],version:[2],arch:[3],repo:[4]}" out=ctable
# Generic / ElasticSearch
- c: ElasticSearch
  s: Cluster
  d: Get an overview of an ElasticSearch/OpenSearch cluster health
  e: |-
    export ES_URL=http://elastic.search:9200
    export ES_EXTRA="--insecure"
    curl -s "$ES_URL/_cat/health?format=json" $ES_EXTRA | oafp out=ctable
- c: ElasticSearch
  s: Indices
  d: Get an ElasticSearch/OpenSearch indices overview
  e: |-
    export ES_URL=http://elastic.search:9200
    export ES_EXTRA="--insecure"
    curl -s "$ES_URL/_cat/indices?format=json&bytes=b" $ES_EXTRA | oafp sql="select * order by index" out=ctable
- c: ElasticSearch
  s: Cluster
  d: Get an ElasticSearch/OpenSearch cluster nodes overview
  e: |-
    export ES_URL=http://elastic.search:9200
    export ES_EXTRA="--insecure"
    curl -s "$ES_URL/_cat/nodes?format=json" $ES_EXTRA | oafp sql="select * order by ip" out=ctable
- c: ElasticSearch
  s: Cluster
  d: Get an ElasticSearch/OpenSearch cluster per host data allocation
  e: |-
    export ES_URL=http://elastic.search:9200
    export ES_EXTRA="--insecure"
    curl -s "$ES_URL/_cat/allocation?format=json&bytes=b" $ES_EXTRA | oafp sql="select * order by host" out=ctable
- c: ElasticSearch
  s: Cluster
  d: Get an ElasticSearch/OpenSearch cluster settings flat
  e: |-
    export ES_URL=http://elastic.search:9200
    export ES_EXTRA="--insecure"
    curl -s "$ES_URL/_cluster/settings?include_defaults=true&flat_settings=true" $ES_EXTRA | oafp out=ctree
- c: ElasticSearch
  s: Cluster
  d: Get an ElasticSearch/OpenSearch cluster settings non-flatted
  e: |-
    export ES_URL=http://elastic.search:9200
    export ES_EXTRA="--insecure"
    curl -s "$ES_URL/_cluster/settings?include_defaults=true" $ES_EXTRA | oafp out=ctree
- c: ElasticSearch
  s: Cluster
  d: Get an ElasticSearch/OpenSearch cluster stats per node
  e: |-
    export ES_URL=http://elastic.search:9200
    export ES_EXTRA="--insecure"
    curl -s "$ES_URL/_nodes/stats/indices/search" $ES_EXTRA | oafp out=ctree
- c: ElasticSearch
  s: Indices
  d: Get an ElasticSearch/OpenSearch settings for a specific index
  e: |-
    export ES_URL=http://elastic.search:9200
    export ES_EXTRA="--insecure"
    curl -s "$ES_URL/kibana_sample_data_flights/_settings" $ES_EXTRA | oafp out=ctree
- c: ElasticSearch
  s: Indices
  d: Get an ElasticSearch/OpenSearch count per index
  e: |-
    export ES_URL=http://elastic.search:9200
    export ES_EXTRA="--insecure"
    curl -s "$ES_URL/kibana_sample_data_flights/_count" $ES_EXTRA | oafp
- c: JSON Schemas
  s: Lists
  d: Get a list of JSON schemas from Schema Store catalog
  e: |-
    oafp cmd="curl https://raw.githubusercontent.com/SchemaStore/schemastore/master/src/api/json/catalog.json" path="schemas[].{name:name,description:description,files:to_string(fileMatch)}" out=ctable
- c: Kubernetes
  s: Kubectl
  d: List of Kubernetes pods per namespace and kind using kubectl
  e: |-
    oafp cmd="kubectl get pods -A -o json" path="items[].{ns:metadata.namespace,kind:metadata.ownerReferences[].kind,name:metadata.name,status:status.phase,restarts:sum(status.containerStatuses[].restartCount),node:spec.nodeName,age:timeago(status.startTime)}" sql="select * order by status,name" output=ctable
- c: Kubernetes
  s: Kubectl
  d: List of Kubernetes CPU, memory and storage stats per node using kubectl
  e: |-
    oafp cmd="kubectl get nodes -o json" path="items[].{node:metadata.name,totalCPU:status.capacity.cpu,allocCPU:status.allocatable.cpu,totalMem:to_bytesAbbr(from_bytesAbbr(status.capacity.memory)),allocMem:to_bytesAbbr(from_bytesAbbr(status.allocatable.memory)),totalStorage:to_bytesAbbr(from_bytesAbbr(status.capacity.\"ephemeral-storage\")),allocStorage:to_bytesAbbr(to_number(status.allocatable.\"ephemeral-storage\")),conditions:join(\`, \`,status.conditions[].reason)}" output=ctable
- c: Kubernetes
  s: Kubectl
  d: Build an output table with Kubernetes pods with namespace, pod name, container name and corresponding resources using kubectl
  e: |-
    kubectl get pods -A -o json | oafp path="items[].amerge({ ns: metadata.namespace, pod: metadata.name, phase: status.phase }, spec.containers[].{ container: name, resources: to_slon(resources) })[]" sql="select ns, pod, container, phase, resources order by ns, pod, container" out=ctable
- c: Kubernetes
  s: Kubectl
  d: Build an output table with Kubernetes pods with node, namespace, pod name, container name and corresponding resources using kubectl
  e: |-
    kubectl get pods -A -o json | oafp path="items[].amerge({ node: spec.nodeName, ns: metadata.namespace, pod: metadata.name, phase: status.phase }, spec.containers[].{ container: name, resources: to_slon(resources) })[]" sql="select node, ns, pod, container, phase, resources order by node, ns, pod, container" out=ctable
- c: AI
  s: Ollama
  d: Setting up access to Ollama and ask for data to an AI LLM model
  e: |-
    export OAFP_MODEL="(type: ollama, model: 'mistral', url: 'https://models.local', timeout: 900000)"
    echo "Output a JSON array with 15 cities where each entry has the 'city' name, the estimated population and the corresponding 'country'" | oafp input=llm output=json > data.json
    oafp data.json output=ctable sql="select * order by population desc"
- c: AI
  s: OpenAI
  d: Setting up the OpenAI LLM model and gather the data into a data.json file
  e: |-
    export OAFP_MODEL="(type: openai, model: gpt-3.5-turbo, key: ..., timeout: 900000)"
    echo "list all United Nations secretaries with their corresponding 'name', their mandate 'begin date', their mandate 'end date' and their corresponding secretary 'numeral'" | oafp input=llm output=json > data.json
- c: OpenAF
  s: oPacks
  d: "Listing all currently accessible OpenAF's oPacks"
  e: |-
    oaf -c "sprint(getOPackRemoteDB())" | oafp maptoarray=true opath="[].{name:name,description:description,version:version}" from="sort(name)" out=ctable
- c: OpenAF
  s: OS
  d: Current OS information visible to OpenAF
  e: |-
    oafp -v path=os
- c: OpenAF
  s: Network
  d: List all network addresses returned from the current DNS server for a hostname using OpenAF
  e: |-
    DOMAIN=yahoo.com && oaf -c "sprint(ow.loadNet().getDNS('$DOMAIN'))" | oafp from="sort(Address)" out=ctable
- c: OpenAF
  s: Network
  d: List all MX (mail servers) network addresses from the current DNS server for a hostname using OpenAF
  e: |-
    DOMAIN=gmail.com && TYPE=MX && oaf -c "sprint(ow.loadNet().getDNS('$DOMAIN','$TYPE'))" | oafp from="sort(Address)" out=ctable
- c: OpenAF
  s: TLS
  d: List the TLS certificates of a target host with a sorted alternative names using OpenAF
  e: |-
    DOMAIN=yahoo.com && oaf -c "sprint(ow.loadNet().getTLSCertificates('$DOMAIN',443))" | oafp path="[].{issuer:issuerDN,subject:subjectDN,notBefore:notBefore,notAfter:notAfter,alternatives:join(' | ',sort(map(&[1],nvl(alternatives,\`[]\`))))}" out=ctree
- c: OpenAF
  s: Channels
  d: "Copy the json result of a command into an etcd database using OpenAF's channels"
  e: |-
    oaf -c "\$o(io.listFiles('.').files,{__format:'json'})" | oafp out=ch ch="(type: etcd3, options: (host: localhost, port: 2379), lib: 'etcd3.js')" chkey=canonicalPath
- c: OpenAF
  s: Channels
  d: "Getting all data stored in an etcd database using OpenAF's channels"
  e: |-
    echo "" | oafp in=ch inch="(type: etcd3, options: (host: localhost, port: 2379), lib: 'etcd3.js')" out=ctable
- c: OpenAF
  s: Channels
  d: "Store the json results of a command into a H2 MVStore file using OpenAF's channels"
  e: |-
    oaf -c "\$o(listFilesRecursive('.'),{__format:'json'})" | oafp out=ch ch="(type: mvs, options: (file: data.db))" chkey=canonicalPath
- c: OpenAF
  s: Channels
  d: "Retrieve all keys stores in a H2 MVStore file using OpenAF's channels"
  e: |-
    echo "" | oafp in=ch inch="(type: mvs, options: (file: data.db))" out=ctable
- c: OpenAF
  s: Channels
  d: "Perform a query to a metric & label, with a start and end time, to a Prometheus server using OpenAF's channels"
  e: |-
    oafp in=ch inch="(type:prometheus,options:(urlQuery:'http://prometheus.local'))" inchall=true data="(start:'2024-03-22T19:00:00.000Z',end:'2024-03-22T19:05:00.000Z',step:60,query:go_memstats_alloc_bytes_total{job=\"prometheus\"})" path="[].values[].{date:to_date(mul([0],to_number('1000'))),value:[1]}" out=ctable
- c: Windows
  s: Network
  d: "Output a table with the list of network interfaces using Windows' PowerShell"
  e: |-
    Get-NetIPAddress | ConvertTo-Json | .\oafp.bat path="[].{ipAddress:IPAddress,prefixLen:PrefixLength,interface:InterfaceAlias}" sql=select\ *\ order\ by\ interface out=ctable
- c: Windows
  s: Network
  d: "Output a table with the current route table using Windows' PowerShell"
  e: |-
    Get-NetRoute | ConvertTo-Json | .\oafp.bat path="[].{destination:DestinationPrefix,gateway:NextHop,interface:InterfaceAlias,metric:InterfaceMetric}" sql=select\ *\ order\ by\ interface,destination out=ctable
- c: Windows
  s: Storage
  d: "Output a table with the attached disk information using Windows' PowerShell"
  e: |-
    Get-Disk | ConvertTo-Csv -NoTypeInformation | .\oafp.bat in=csv path="[].{id:trim(UniqueId),name:FriendlyName,isBoot:IsBoot,location:Location,size:to_bytesAbbr(to_number(Size)),allocSize:to_bytesAbbr(to_number(AllocatedSize)),sectorSize:LogicalSectorSize,phySectorSize:PhysicalSectorSize,numPartitions:NumberOfPartitions,partitioning:PartitionStyle,health:HealthStatus,bus:BusType,manufacturer:Manufacturer,model:Model,firmwareVersion:FirmwareVersion,serialNumber:SerialNumber}" out=ctable
- c: Windows
  s: PnP
  d: "Output a table with USB/PnP devices using Windows' PowerShell"
  e: |-
    Get-PnpDevice -PresentOnly | ConvertTo-Csv -NoTypeInformation | .\oafp.bat in=csv path="[].{class:PNPClass,service:Service,name:FriendlyName,id:InstanceId,description:Description,deviceId:DeviceID,status:Status,present:Present}" sql=select\ *\ order\ by\ class,service out=ctable
- c: Chart
  s: Unix
  d: "Output a chart with the current Unix load using uptime"
  e: |-
    oafp cmd="uptime" in=raw path="replace(trim(@), '.+ ([\d\.]+),? ([\d\.]+),? ([\d\.]+)\$', '', '\$1|\$2|\$3').split(@,'|')" out=chart chart="dec2 [0]:green:load -min:0" loop=1 loopcls=true
- c: APIs
  s: Network
  d: Generating a simple map of the current public IP address
  e: |-
    curl -s https://ifconfig.co/json | oafp flatmap=true out=map
- c: APIs
  s: Network
  d: Converting the Cloudflare DNS trace info
  e: |-
    curl -s https://1.1.1.1/cdn-cgi/trace | oafp in=ini out=ctree
- c: APIs
  s: Network
  d: Converting the Google DNS DoH query result
  e: |-
    DOMAIN=yahoo.com && oafp path=Answer from="sort(data)" out=ctable url="https://8.8.8.8/resolve?name=$DOMAIN&type=a"
- c: OpenAF
  s: oafp
  d: "List the OpenAF's oafp examples by category, sub-category and description"
  e: |-
    oafp url="https://ojob.io/oafp-examples.yaml" in=yaml path="data[].{category:c,subCategory:s,description:d}" from="sort(category,subCategory,description)" out=ctable
- c: OpenAF
  s: oafp
  d: "Filter the OpenAF's oafp examples list by a specific word in the description"
  e: |-
    oafp url="https://ojob.io/oafp-examples.yaml" in=yaml out=template path=data templatepath=tmpl sql="select * where d like '%something%'"
- c: AI
  s: Summarize
  d: "Use an AI LLM model to summarize the weather information provided in a JSON format"
  e: |-
    export OAFP_MODEL="(type: openai, model: 'gpt-3.5-turbo', key: '...', timeout: 900000)"
    oafp url="https://wttr.in?format=j2" llmcontext="current and forecast weather" llmprompt="produce a summary of the current and forecasted weather" out=md
- c: AI
  s: Prompt
  d: Example of generating data from an AI LLM prompt
  e: |-
    export OAFP_MODEL="(type: openai, model: 'gpt-3.5-turbo', key: '...', timeout: 900000)"
    oafp in=llm data="produce a list of 25 species of 'flowers' with their english and latin name and the continent where it can be found" out=json > data.json
- c: Generic
  s: RSS
  d: Example of generating a HTML list of titles, links and publication dates from a RSS feed
  e: |-
    oafp url="https://blog.google/rss" path="rss.channel.item" sql="select title, link, pubDate" output=html
- c: Mac
  s: Info
  d: Parses the current Mac OS overview information
  e: |-
    system_profiler SPSoftwareDataType -json | oafp path="SPSoftwareDataType[0]" out=ctree
- c: AWS
  s: EC2
  d: Given all AWS EC2 instances in an account produces a table with name, type, vpc and private ip sorted by vpc
  e: |-
    aws ec2 describe-instances | ./oafp path="Reservations[].Instances[].{name:join('',Tags[?Key=='Name'].Value),type:InstanceType,vpc:VpcId,ip:PrivateIpAddress} | sort_by(@, &vpc)" output=ctable
- c: AWS
  s: EKS
  d: "Builds an excel spreadsheet with all persistent volumes associated with an AWS EKS 'XYZ' with the corresponding Kubernetes namespace, pvc and pv names"
  e: |-
    # sudo yum install -y fontconfig
    aws ec2 describe-volumes | oafp path="Volumes[?Tags[?Key=='kubernetes.io/cluster/XYZ']|[0].Value=='owned'].{VolumeId:VolumeId,Name:Tags[?Key=='Name']|[0].Value,KubeNS:Tags[?Key=='kubernetes.io/created-for/pvc/namespace']|[0].Value,KubePVC:Tags[?Key=='kubernetes.io/created-for/pvc/name']|[0].Value,KubePV:Tags[?Key=='kubernetes.io/created-for/pv/name']|[0].Value,AZ:AvailabilityZone,Size:Size,Type:VolumeType,CreateTime:CreateTime,State:State,AttachTime:join(',',nvl(Attachments[].AttachTime,from_slon('[]'))[]),InstanceId:join(',',nvl(Attachments[].InstanceId,from_slon('[]'))[])}" from="sort(KubeNS,KubePVC)" out=xls xlsfile=xyz_pvs.xlsx
- c: GitHub
  s: Releases
  d: "Builds a table of GitHub project releases"
  e: |-
    curl -s https://api.github.com/repos/openaf/openaf/releases | oafp sql="select name, tag_name, published_at order by published_at" output=ctable
- c: GitHub
  s: Releases
  d: "Parses the latest GitHub project release markdown notes"
  e: |-
    curl -s https://api.github.com/repos/openaf/openaf/releases | oafp path="[0].body" output=md
- c: OpenAF
  s: Channels
  d: "Store and retrieve data from a RocksDB database"
  e: |-
    # Install rocksdb opack: 'opack install rocksdb'
    #
    # Storing data
    oafp cmd="oaf -c \"sprint(listFilesRecursive('/usr/bin'))\"" out=ch ch="(type: rocksdb, lib: rocksdb.js, options: (path: db))" chkey=canonicalPath
    # Retrieve data
    echo "" | oafp in=ch inch="(type: rocksdb, lib: rocksdb.js, options: (path: db))" out=pjson
- c: OpenAF
  s: Channels
  d: "Store and retrieve data from a Redis database"
  e: |-
    # Install rocksdb opack: 'opack install redis'
    #
    # Storing data
    oafp cmd="oaf -c \"sprint(listFilesRecursive('/usr/bin'))\"" out=ch ch="(type: redis, lib: redis.js, options: (host: '127.0.0.1', port: 6379))" chkey=canonicalPath
    # Retrieve data
    echo "" | oafp in=ch inch="(type: redis, lib: redis.js, options: (host: '127.0.0.1', port: 6379))" out=pjson
- c: Generic
  s: Excel
  d: "Store and retrieve data from an Excel spreadsheet"
  e: |-
    # Storing data
    oafp cmd="oaf -c \"sprint(listFilesRecursive('/usr/bin'))\"" out=xls xlsfile=data.xlsx
    # Retrieve data
    oafp in=xls file=data.xlsx xlscol=A xlsrow=1 out=pjson
- c: Kubernetes
  s: Containers
  d: "Parse the Linux cgroup cpu stats on a container running in Kubernetes"
  e: |-
    cat /sys/fs/cgroup/cpu.stat | sed 's/ /: /g' | oafp in=yaml out=ctree
- c: Grid
  s: Kubernetes
  d: "Displays a continuous updating grid with a line chart with the number of CPU throtlles and bursts recorded in the Linux cgroup cpu stats of a container running in Kubernetes and the source cpu.stats data"
  e: |-
    oafp cmd="cat /sys/fs/cgroup/cpu.stat | sed 's/ /: /g'" in=yaml out=grid grid="[[(title:cpu.stat,type:tree)|(title:chart,type:chart,obj:'int nr_throttled:red:throttled nr_bursts:blue:bursts -min:0 -vsize:10')]]" loop=1
- c: AWS
  s: Lambda
  d: Prepares a table of AWS Lambda functions with their corresponding main details
  e: |-
    aws lambda list-functions | oafp path="Functions[].{Name:FunctionName,Runtime:Runtime,Arch:join(',',Architectures),Role:Role,MemorySize:MemorySize,EphStore:EphemeralStorage.Size,CodeSize:CodeSize,LastModified:LastModified}" from="sort(Name)" out=ctable
- c: AI 
  s: Conversation
  d: Send multiple requests to an OpenAI model keeping the conversation between interactions and setting the temperature parameter
  e: |-
    export OAFP_MODEL="(type: openai, model: 'gpt-3.5-turbo-0125', key: ..., timeout: 900000, temperature: 0)"
    echo "List all countries in the european union" | oafp in=llm out=ctree llmconversation=cvst.json
    echo "Add the corresponding country capital" | oafp in=llm out=ctree llmconversation=cvst.json
    rm cvst.json
- c: AWS
  s: Lambda
  d: Prepares a table, for a specific AWS Lambda function during a specific time periods, with number of invocations and minimum, average and maximum duration per periods from AWS CloudWatch
  e: |-
    export _SH="aws cloudwatch get-metric-statistics --namespace AWS/Lambda --start-time 2024-03-01T00:00:00Z --end-time 2024-04-01T00:00:00Z --period 3600 --dimensions Name=FunctionName,Value=my-function"
    $_SH --statistics Sum --metric-name Invocations  | oafp path="Datapoints[].{ts:Timestamp,cnt:Sum}" out=ndjson > data.ndjson
    $_SH --statistics Average --metric-name Duration | oafp path="Datapoints[].{ts:Timestamp,avg:Average}" out=ndjson >> data.ndjson
    $_SH --statistics Minimum --metric-name Duration | oafp path="Datapoints[].{ts:Timestamp,min:Minimum}" out=ndjson >> data.ndjson
    $_SH --statistics Maximum --metric-name Duration | oafp path="Datapoints[].{ts:Timestamp,max:Maximum}" out=ndjson >> data.ndjson
    oafp data.ndjson ndjsonjoin=true opath="[].{ts:ts,cnt:nvl(cnt,\`0\`),min:nvl(min,\`0\`),avg:nvl(avg,\`0\`),max:nvl(max,\`0\`)}" out=json | oafp isql="select \"ts\",max(\"cnt\") \"cnt\",max(\"min\") \"min\",max(\"avg\") \"avg\",max(\"max\") \"max\" group by \"ts\" order by \"ts\"" opath="[].{ts:ts,cnt:cnt,min:from_ms(min,'(abrev:true,pad:true)'),avg:from_ms(avg,'(abrev:true,pad:true)'),max:from_ms(max,'(abrev:true,pad:true)')}" out=ctable
- c: Generic
  s: Arrays
  d: Converting an array of strings into an array of maps
  e: |-
    oafp -v path="java.params[].insert(from_json('{}'), 'param', @).insert(@, 'len', length(param))"
- c: Grid
  s: Mac
  d: Shows a grid with the Mac network metrics and 4 charts for in, out packets and in, out bytes
  e: |-
    # opack install mac
    sudo powermetrics --help > /dev/null
    oafp libs=Mac cmd="sudo powermetrics --format=plist --show-initial-usage -n 0 --samplers network" in=plist path=network out=grid grid="[[(title:data,path:@,xsnap:2)]|[(title:in packets,type:chart,obj:'int ipackets:blue:in')|(title:out packets,type:chart,obj:'int opackets:red:out')]|[(title:in bytes,type:chart,obj:'int ibytes:blue:in')|(title:out bytes,type:chart,obj:'int obytes:red:out')]]" loop=1
- c: Grid
  s: Mac
  d: Shows a grid with the Mac storage metrics and 4 charts for read, write IOPS and read, write bytes per second
  e: |-
    # opack install mac
    sudo powermetrics --help > /dev/null
    oafp libs=Mac cmd="sudo powermetrics --format=plist --show-initial-usage -n 0 --samplers disk" in=plist path=disk out=grid grid="[[(title:data,path:@,xsnap:2)]|[(title:read iops,type:chart,obj:'dec3 rops_per_s:blue:read_iops')|(title:write iops,type:chart,obj:'dec3 wops_per_s:red:write_iops')]|[(title:read bytes per sec,type:chart,obj:'bytes rbytes_per_s:blue:read_bytes_per_sec')|(title:write bytes per sec,type:chart,obj:'bytes wbytes_per_s:red:write_bytes_per_sec')]]" loop=1
- c: Generic
  s: RSS
  d: Builds an HTML file with the current linked news titles, publication date and source from Google News.
  e: |-
    oafp url="https://news.google.com/rss" path="rss.channel.item[].{title:replace(t(@,'[{{title}}]({{link}})'),'\|','g','\\|'),date:pubDate,source:source._}" from="sort(-date)" out=mdtable | oafp in=md out=html
- c: Mac
  s: Safari
  d: Get a list of all Mac OS Safari bookmarks into a CSV file.
  e: |-
    # opack install mac
    oafp ~/Library/Safari/Bookmarks.plist libs=Mac path="Children[].map(&{category:get('cat'),title:URIDictionary.title,url:URLString},setp(@,'Title','cat').nvl(Children,from_json('[]')))[][]" out=csv > bookmarks.csv
- c: Docker
  s: Listing
  d: List all containers with their corresponding labels parsed and sorted.
  e: |-
    docker ps -a --format=json | oafp in=ndjson ndjsonjoin=true out=ctree path="[].insert(@,'Labels',sort_by(split(Labels,',')[].split(@,'=').{key:[0],value:[1]},&key))" out=ctree
- c: Docker
  s: Listing
  d: List all containers with the docker-compose project, service name, file, id, name, image, creation time, status, networks and ports.
  e: |-
    docker ps -a --format=json | oafp in=ndjson ndjsonjoin=true out=ctree path="[].insert(@,'Labels',sort_by(split(Labels,',')[].split(@,'=').{key:[0],value:[1]},&key))" out=json | oafp path="[].{dcProject:nvl(Labels[?key=='com.docker.compose.project']|[0].value,''),dcService:nvl(Labels[?key=='com.docker.compose.service']|[0].value,''),ID:ID,Names:Names,Image:Image,Created:RunningFor,Status:Status,Ports:Ports,Networks:Networks,dcFile:nvl(Labels[?key=='com.docker.compose.project.config_files']|[0].value,'')}" sql="select * order by dcProject,dcService,Networks,Names" out=ctable
- c: Grid
  s: Unix
  d: "On an Unix/Linux system supporting 'ps' output formats %cpu and %mem, will output a chart with the percentage of cpu and memory usage of a provided pid (e.g. 12345)"
  e: |-
    oafp cmd="ps -p 12345 -o %cpu,%mem" in=lines linesvisual=true linesvisualsepre="\\s+" out=chart chart="int '\"%CPU\"':red:cpu '\"%MEM\"':blue:mem -min:0 -max:100" loop=1 loopcls=true
- c: Generic
  s: Hex
  d: Outputs an hexadecimal representation of the characters of the file provided allowing to adjust how many per line/row.
  e: |-
    oafp some.file in=rawhex inrawhexline=15 out=ctable
- c: Unix
  s: Activity
  d: "Uses the Linux command 'last' output to build a table with user, tty, from and period of activity"
  e: |-
    oafp cmd="last" in=lines linesjoin=true path="[:-3]|[?contains(@,'no logout')==\`false\`&&contains(@,'system boot')==\`false\`].split_re(@,' \\s+').{user:[0],tty:[1],from:[2],period:join(' ',[3:])}" out=ctable
- c: Mac
  s: Activity
  d: "Uses the Mac terminal command 'last' output to build an activity table with user, tty, from, login-time and logout-time"
  e: |-
    oafp cmd="last --libxo json" path="\"last-information\".last" out=ctable
- c: OpenAF
  s: OS
  d: Using OpenAF parse the current environment variables
  e: |-
    oaf -c "sprint(getEnvs())" | oafp sortmapkeys=true out=ctree
- c: APIs
  s: iTunes
  d: "Search the Apple's iTunes database for a specific term"
  e: |-
    TRM="Mozart" && oafp url="https://itunes.apple.com/search?term=$TRM" out=ctree
- c: APIs
  s: Public Holidays
  d: "Return the public holidays for a given country on a given year"
  e: |-
    COUNTRY=US && YEAR=2024 && oafp url="https://date.nager.at/api/v2/publicholidays/$YEAR/$COUNTRY" path="[].{date:date,localName:localName,name:name}" out=ctable
